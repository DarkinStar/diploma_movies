{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317fcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wiki_movie_plots_deduped_with_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93a13fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'genre', 'plot', 'summary', 'release_year'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df[['Title', 'Genre', 'Plot', 'PlotSummary', 'Release Year']]\n",
    "df = df.rename(columns={\n",
    "    'Title': 'title',\n",
    "    'Genre': 'genre',\n",
    "    'Plot': 'plot',\n",
    "    'PlotSummary': 'summary',\n",
    "    'Release Year': 'release_year'\n",
    "})\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbe44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['title', 'genre', 'plot', 'summary', 'release_year'])\n",
    "\n",
    "# Remove rows with empty strings or just spaces\n",
    "df = df[\n",
    "    (df['title'].str.strip() != '') &\n",
    "    (df['genre'].str.strip() != '') &\n",
    "    (df['plot'].str.strip() != '') &\n",
    "    (df['summary'].str.strip() != '')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces/newlines\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\"-]', '', text)  # remove weird symbols\n",
    "    return text.strip()\n",
    "\n",
    "df['plot'] = df['plot'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6d4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915ac748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to cleaned_movie_plots.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"cleaned_movie_plots.csv\", index=False)\n",
    "print(\"Data cleaned and saved to cleaned_movie_plots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44488b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yazan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating plot 0/32406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yazan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4096: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating plot 50/32406\n",
      "Translating plot 100/32406\n",
      "Translating plot 150/32406\n",
      "Translating plot 200/32406\n",
      "Translating plot 250/32406\n",
      "Translating plot 300/32406\n",
      "Translating plot 350/32406\n",
      "Translating plot 400/32406\n",
      "Translating plot 450/32406\n",
      "Translating plot 500/32406\n",
      "Translating plot 550/32406\n",
      "Translating plot 600/32406\n",
      "Translating plot 650/32406\n",
      "Translating plot 700/32406\n",
      "Translating plot 750/32406\n",
      "Translating plot 800/32406\n",
      "Translating plot 850/32406\n",
      "Translating plot 900/32406\n",
      "Translating plot 950/32406\n",
      "Translating plot 1000/32406\n",
      "Translating plot 1050/32406\n",
      "Translating plot 1100/32406\n",
      "Translating plot 1150/32406\n",
      "Translating plot 1200/32406\n",
      "Translating plot 1250/32406\n",
      "Translating plot 1300/32406\n",
      "Translating plot 1350/32406\n",
      "Translating plot 1400/32406\n",
      "Translating plot 1450/32406\n",
      "Translating plot 1500/32406\n",
      "Translating plot 1550/32406\n",
      "Translating plot 1600/32406\n",
      "Translating plot 1650/32406\n",
      "Translating plot 1700/32406\n",
      "Translating plot 1750/32406\n",
      "Translating plot 1800/32406\n",
      "Translating plot 1850/32406\n",
      "Translating plot 1900/32406\n",
      "Translating plot 1950/32406\n",
      "Translating plot 2000/32406\n",
      "Translating plot 2050/32406\n",
      "Translating plot 2100/32406\n",
      "Translating plot 2150/32406\n",
      "Translating plot 2200/32406\n",
      "Translating plot 2250/32406\n",
      "Translating plot 2300/32406\n",
      "Translating plot 2350/32406\n",
      "Translating plot 2400/32406\n",
      "Translating plot 2450/32406\n",
      "Translating plot 2500/32406\n",
      "Translating plot 2550/32406\n",
      "Translating plot 2600/32406\n",
      "Translating plot 2650/32406\n",
      "Translating plot 2700/32406\n",
      "Translating plot 2750/32406\n",
      "Translating plot 2800/32406\n",
      "Translating plot 2850/32406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('cleaned_movie_plots.csv')\n",
    "\n",
    "# Load MarianMT English->Russian model and tokenizer\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate_marionmt(text):\n",
    "    if not isinstance(text, str) or text.strip() == '':\n",
    "        return ''\n",
    "    # Tokenize input\n",
    "    batch = tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\")\n",
    "    # Generate translation ids\n",
    "    generated_ids = model.generate(**batch)\n",
    "    # Decode translation\n",
    "    translated = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return translated\n",
    "\n",
    "# Add a new column for Russian translations\n",
    "df['plot_ru'] = ''\n",
    "\n",
    "# Translate each plot (you can add a progress bar or just print status)\n",
    "for idx, plot in enumerate(df['plot']):\n",
    "    if idx % 50 == 0:\n",
    "        print(f'Translating plot {idx}/{len(df)}')\n",
    "    df.at[idx, 'plot_ru'] = translate_marionmt(plot)\n",
    "\n",
    "# Save the dataset with Russian plots\n",
    "df.to_csv('movie_plots_with_russian_offline.csv', index=False)\n",
    "print(\"Offline translation done! Saved as movie_plots_with_russian_offline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414d62c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved progress to checkpoint_before_stop.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('checkpoint_before_stop.csv', index=False)\n",
    "print(\"✅ Saved progress to checkpoint_before_stop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c17a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
